
@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2018-03-21},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1409.1556 PDF:/Users/fernando/Zotero/storage/VIRJDK2W/Simonyan and Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/EUI9Z7WL/1409.html:text/html}
}

@article{maninis_deep_2016,
	title = {Deep {Retinal} {Image} {Understanding}},
	volume = {9901},
	url = {http://arxiv.org/abs/1609.01103},
	doi = {10.1007/978-3-319-46723-8_17},
	abstract = {This paper presents Deep Retinal Image Understanding (DRIU), a unified framework of retinal image analysis that provides both retinal vessel and optic disc segmentation. We make use of deep Convolutional Neural Networks (CNNs), which have proven revolutionary in other fields of computer vision such as object detection and image classification, and we bring their power to the study of eye fundus images. DRIU uses a base network architecture on which two set of specialized layers are trained to solve both the retinal vessel and optic disc segmentation. We present experimental validation, both qualitative and quantitative, in four public datasets for these tasks. In all of them, DRIU presents super-human performance, that is, it shows results more consistent with a gold standard than a second human annotator used as control.},
	urldate = {2018-03-21},
	journal = {arXiv:1609.01103 [cs]},
	author = {Maninis, Kevis-Kokitsi and Pont-Tuset, Jordi and Arbeláez, Pablo and Van Gool, Luc},
	year = {2016},
	note = {arXiv: 1609.01103},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {140--148},
	file = {arXiv\:1609.01103 PDF:/Users/fernando/Zotero/storage/23SJUZ7D/Maninis et al. - 2016 - Deep Retinal Image Understanding.pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/RH9V2I6L/1609.html:text/html}
}

@incollection{sudre_generalised_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Generalised {Dice} {Overlap} as a {Deep} {Learning} {Loss} {Function} for {Highly} {Unbalanced} {Segmentations}},
	isbn = {978-3-319-67557-2 978-3-319-67558-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-67558-9_28},
	abstract = {Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks.},
	language = {en},
	urldate = {2018-03-20},
	booktitle = {Deep {Learning} in {Medical} {Image} {Analysis} and {Multimodal} {Learning} for {Clinical} {Decision} {Support}},
	publisher = {Springer, Cham},
	author = {Sudre, Carole H. and Li, Wenqi and Vercauteren, Tom and Ourselin, Sebastien and Cardoso, M. Jorge},
	month = sep,
	year = {2017},
	doi = {10.1007/978-3-319-67558-9_28},
	pages = {240--248},
	file = {Full Text PDF:/Users/fernando/Zotero/storage/QISRLZXY/Sudre et al. - 2017 - Generalised Dice Overlap as a Deep Learning Loss F.pdf:application/pdf;Snapshot:/Users/fernando/Zotero/storage/GU5ZHHAV/978-3-319-67558-9_28.html:text/html}
}

@inproceedings{frangi_multiscale_1998,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multiscale vessel enhancement filtering},
	isbn = {978-3-540-65136-9 978-3-540-49563-5},
	url = {https://link.springer.com/chapter/10.1007/BFb0056195},
	doi = {10.1007/BFb0056195},
	abstract = {The multiscale second order local structure of an image (Hessian) is examined with the purpose of developing a vessel enhancement filter. A vesselness measure is obtained on the basis of all eigenvalues of the Hessian. This measure is tested on two dimensional DSA and three dimensional aortoiliac and cerebral MRA data. Its clinical utility is shown by the simultaneous noise and background suppression and vessel enhancement in maximum intensity projections and volumetric displays.},
	language = {en},
	urldate = {2018-03-20},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} — {MICCAI}’98},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Frangi, Alejandro F. and Niessen, Wiro J. and Vincken, Koen L. and Viergever, Max A.},
	month = oct,
	year = {1998},
	pages = {130--137},
	file = {Full Text PDF:/Users/fernando/Zotero/storage/A55ZFESQ/Frangi et al. - 1998 - Multiscale vessel enhancement filtering.pdf:application/pdf;Snapshot:/Users/fernando/Zotero/storage/PUMWZISX/BFb0056195.html:text/html}
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1532-4435},
	shorttitle = {Scikit-learn},
	url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	urldate = {2018-03-20},
	journal = {J. Mach. Learn. Res.},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = nov,
	year = {2011},
	pages = {2825--2830},
	file = {ACM Full Text PDF:/Users/fernando/Zotero/storage/BSJSAHQP/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf}
}

@article{staal_ridge-based_2004,
	title = {Ridge-based vessel segmentation in color images of the retina},
	volume = {23},
	issn = {0278-0062},
	doi = {10.1109/TMI.2004.825627},
	abstract = {A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. and Jiang et al. . The results show that our method is significantly better than the two rule-based methods (p{\textless}0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.},
	number = {4},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Staal, J. and Abramoff, M. D. and Niemeijer, M. and Viergever, M. A. and Ginneken, B. van},
	month = apr,
	year = {2004},
	keywords = {medical image processing, image segmentation, feature extraction, Image segmentation, eye, Algorithms, automated segmentation, classifier, Cluster Analysis, Color, Databases, Factual, Diabetes, diabetic retinopathy, Diabetic Retinopathy, Expert Systems, Fluorescein Angiography, Humans, Image analysis, Image databases, Image Interpretation, Computer-Assisted, image ridge extraction, Ophthalmoscopy, Pattern Recognition, Automated, Pixel, Reproducibility of Results, retina, Retina, Retinal Vessels, Retinopathy, ridge-based vessel segmentation, Sensitivity and Specificity, sequential forward feature selection, Spatial databases, Testing, two-dimensional color images},
	pages = {501--509},
	file = {IEEE Xplore Abstract Record:/Users/fernando/Zotero/storage/PPGPQW8R/1282003.html:text/html;IEEE Xplore Full Text PDF:/Users/fernando/Zotero/storage/4EKSV8BE/Staal et al. - 2004 - Ridge-based vessel segmentation in color images of.pdf:application/pdf}
}

@article{geurts_extremely_2006,
	title = {Extremely randomized trees},
	volume = {63},
	issn = {0885-6125, 1573-0565},
	url = {https://link.springer.com/article/10.1007/s10994-006-6226-1},
	doi = {10.1007/s10994-006-6226-1},
	abstract = {This paper proposes a new tree-based ensemble method for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.},
	language = {en},
	number = {1},
	urldate = {2018-03-20},
	journal = {Machine Learning},
	author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
	month = apr,
	year = {2006},
	pages = {3--42},
	file = {Full Text PDF:/Users/fernando/Zotero/storage/6IY22MIW/Geurts et al. - 2006 - Extremely randomized trees.pdf:application/pdf;Snapshot:/Users/fernando/Zotero/storage/9EM8ZDWA/s10994-006-6226-1.html:text/html}
}

@article{xie_holistically-nested_2015,
	title = {Holistically-{Nested} {Edge} {Detection}},
	url = {http://arxiv.org/abs/1504.06375},
	abstract = {We develop a new edge detection algorithm that tackles two important issues in this long-standing vision problem: (1) holistic image training and prediction; and (2) multi-scale and multi-level feature learning. Our proposed method, holistically-nested edge detection (HED), performs image-to-image prediction by means of a deep learning model that leverages fully convolutional neural networks and deeply-supervised nets. HED automatically learns rich hierarchical representations (guided by deep supervision on side responses) that are important in order to approach the human ability resolve the challenging ambiguity in edge and object boundary detection. We significantly advance the state-of-the-art on the BSD500 dataset (ODS F-score of .782) and the NYU Depth dataset (ODS F-score of .746), and do so with an improved speed (0.4 second per image) that is orders of magnitude faster than some recent CNN-based edge detection algorithms.},
	urldate = {2018-03-23},
	journal = {arXiv:1504.06375 [cs]},
	author = {Xie, Saining and Tu, Zhuowen},
	month = apr,
	year = {2015},
	note = {arXiv: 1504.06375},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1504.06375 PDF:/Users/fernando/Zotero/storage/CQP955IB/Xie and Tu - 2015 - Holistically-Nested Edge Detection.pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/WT8CF3I8/1504.html:text/html}
}

@misc{noauthor_conda_nodate,
	title = {Conda — {Conda} documentation},
	url = {https://conda.io/docs/},
	urldate = {2018-03-23},
	file = {Conda — Conda documentation:/Users/fernando/Zotero/storage/MH8HEQ3M/docs.html:text/html}
}

@misc{noauthor_docker_nodate,
	title = {Docker},
	url = {https://www.docker.com/},
	abstract = {Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications, whether on laptops, data center VMs, or the cloud., Docker},
	language = {en},
	urldate = {2018-03-23},
	journal = {Docker},
	file = {Snapshot:/Users/fernando/Zotero/storage/YNASE7RN/www.docker.com.html:text/html}
}

@article{ronneberger_u-net:_2015,
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	shorttitle = {U-{Net}},
	url = {http://arxiv.org/abs/1505.04597},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	urldate = {2018-03-23},
	journal = {arXiv:1505.04597 [cs]},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	month = may,
	year = {2015},
	note = {arXiv: 1505.04597},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1505.04597 PDF:/Users/fernando/Zotero/storage/QQIFBJWM/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/L34DW5ZA/1505.html:text/html}
}

@article{fidon_generalised_2018,
	title = {Generalised {Wasserstein} {Dice} {Score} for {Imbalanced} {Multi}-class {Segmentation} using {Holistic} {Convolutional} {Networks}},
	volume = {10670},
	url = {http://arxiv.org/abs/1707.00478},
	doi = {10.1007/978-3-319-75238-9_6},
	abstract = {The Dice score is widely used for binary segmentation due to its robustness to class imbalance. Soft generalisations of the Dice score allow it to be used as a loss function for training convolutional neural networks (CNN). Although CNNs trained using mean-class Dice score achieve state-of-the-art results on multi-class segmentation, this loss function does neither take advantage of inter-class relationships nor multi-scale information. We argue that an improved loss function should balance misclassifications to favour predictions that are semantically meaningful. This paper investigates these issues in the context of multi-class brain tumour segmentation. Our contribution is threefold. 1) We propose a semantically-informed generalisation of the Dice score for multi-class segmentation based on the Wasserstein distance on the probabilistic label space. 2) We propose a holistic CNN that embeds spatial information at multiple scales with deep supervision. 3) We show that the joint use of holistic CNNs and generalised Wasserstein Dice scores achieves segmentations that are more semantically meaningful for brain tumour segmentation.},
	urldate = {2018-03-23},
	journal = {arXiv:1707.00478 [cs]},
	author = {Fidon, Lucas and Li, Wenqi and Garcia-Peraza-Herrera, Luis C. and Ekanayake, Jinendra and Kitchen, Neil and Ourselin, Sebastien and Vercauteren, Tom},
	year = {2018},
	note = {arXiv: 1707.00478},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {64--76},
	file = {arXiv\:1707.00478 PDF:/Users/fernando/Zotero/storage/R4PIDJ7B/Fidon et al. - 2018 - Generalised Wasserstein Dice Score for Imbalanced .pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/T7CVI2UH/1707.html:text/html}
}

@article{jia_caffe:_2014,
	title = {Caffe: {Convolutional} {Architecture} for {Fast} {Feature} {Embedding}},
	shorttitle = {Caffe},
	url = {http://arxiv.org/abs/1408.5093},
	abstract = {Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (\${\textbackslash}approx\$ 2.5 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia.},
	urldate = {2018-03-26},
	journal = {arXiv:1408.5093 [cs]},
	author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
	month = jun,
	year = {2014},
	note = {arXiv: 1408.5093},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1408.5093 PDF:/Users/fernando/Zotero/storage/5A3GBXRX/Jia et al. - 2014 - Caffe Convolutional Architecture for Fast Feature.pdf:application/pdf;arXiv.org Snapshot:/Users/fernando/Zotero/storage/KRW442VI/1408.html:text/html}
}