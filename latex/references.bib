
@article{geurts_extremely_2006,
	title = {Extremely randomized trees},
	volume = {63},
	issn = {0885-6125, 1573-0565},
	url = {https://link.springer.com/article/10.1007/s10994-006-6226-1},
	doi = {10.1007/s10994-006-6226-1},
	abstract = {This paper proposes a new tree-based ensemble method for supervised classification and regression problems. It essentially consists of randomizing strongly both attribute and cut-point choice while splitting a tree node. In the extreme case, it builds totally randomized trees whose structures are independent of the output values of the learning sample. The strength of the randomization can be tuned to problem specifics by the appropriate choice of a parameter. We evaluate the robustness of the default choice of this parameter, and we also provide insight on how to adjust it in particular situations. Besides accuracy, the main strength of the resulting algorithm is computational efficiency. A bias/variance analysis of the Extra-Trees algorithm is also provided as well as a geometrical and a kernel characterization of the models induced.},
	language = {en},
	number = {1},
	urldate = {2018-03-20},
	journal = {Machine Learning},
	author = {Geurts, Pierre and Ernst, Damien and Wehenkel, Louis},
	month = apr,
	year = {2006},
	pages = {3--42},
	file = {Full Text PDF:/home/fernando/Zotero/storage/6IY22MIW/Geurts et al. - 2006 - Extremely randomized trees.pdf:application/pdf;Snapshot:/home/fernando/Zotero/storage/9EM8ZDWA/s10994-006-6226-1.html:text/html}
}

@article{staal_ridge-based_2004,
	title = {Ridge-based vessel segmentation in color images of the retina},
	volume = {23},
	issn = {0278-0062},
	doi = {10.1109/TMI.2004.825627},
	abstract = {A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. and Jiang et al. . The results show that our method is significantly better than the two rule-based methods (p{\textless}0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.},
	number = {4},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Staal, J. and Abramoff, M. D. and Niemeijer, M. and Viergever, M. A. and Ginneken, B. van},
	month = apr,
	year = {2004},
	keywords = {Algorithms, automated segmentation, classifier, Cluster Analysis, Color, Databases, Factual, Diabetes, diabetic retinopathy, Diabetic Retinopathy, Expert Systems, eye, feature extraction, Fluorescein Angiography, Humans, Image analysis, Image databases, Image Interpretation, Computer-Assisted, image ridge extraction, image segmentation, Image segmentation, medical image processing, Ophthalmoscopy, Pattern Recognition, Automated, Pixel, Reproducibility of Results, retina, Retina, Retinal Vessels, Retinopathy, ridge-based vessel segmentation, Sensitivity and Specificity, sequential forward feature selection, Spatial databases, Testing, two-dimensional color images},
	pages = {501--509},
	file = {IEEE Xplore Abstract Record:/home/fernando/Zotero/storage/PPGPQW8R/1282003.html:text/html;IEEE Xplore Full Text PDF:/home/fernando/Zotero/storage/4EKSV8BE/Staal et al. - 2004 - Ridge-based vessel segmentation in color images of.pdf:application/pdf}
}

@article{pedregosa_scikit-learn:_2011,
	title = {Scikit-learn: {Machine} {Learning} in {Python}},
	volume = {12},
	issn = {1532-4435},
	shorttitle = {Scikit-learn},
	url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
	abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
	urldate = {2018-03-20},
	journal = {J. Mach. Learn. Res.},
	author = {Pedregosa, Fabian and Varoquaux, Gaël and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Vanderplas, Jake and Passos, Alexandre and Cournapeau, David and Brucher, Matthieu and Perrot, Matthieu and Duchesnay, Édouard},
	month = nov,
	year = {2011},
	pages = {2825--2830},
	file = {ACM Full Text PDF:/home/fernando/Zotero/storage/BSJSAHQP/Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf:application/pdf}
}

@inproceedings{frangi_multiscale_1998,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Multiscale vessel enhancement filtering},
	isbn = {978-3-540-65136-9 978-3-540-49563-5},
	url = {https://link.springer.com/chapter/10.1007/BFb0056195},
	doi = {10.1007/BFb0056195},
	abstract = {The multiscale second order local structure of an image (Hessian) is examined with the purpose of developing a vessel enhancement filter. A vesselness measure is obtained on the basis of all eigenvalues of the Hessian. This measure is tested on two dimensional DSA and three dimensional aortoiliac and cerebral MRA data. Its clinical utility is shown by the simultaneous noise and background suppression and vessel enhancement in maximum intensity projections and volumetric displays.},
	language = {en},
	urldate = {2018-03-20},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} — {MICCAI}’98},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Frangi, Alejandro F. and Niessen, Wiro J. and Vincken, Koen L. and Viergever, Max A.},
	month = oct,
	year = {1998},
	pages = {130--137},
	file = {Full Text PDF:/home/fernando/Zotero/storage/A55ZFESQ/Frangi et al. - 1998 - Multiscale vessel enhancement filtering.pdf:application/pdf;Snapshot:/home/fernando/Zotero/storage/PUMWZISX/BFb0056195.html:text/html}
}

@incollection{sudre_generalised_2017,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Generalised {Dice} {Overlap} as a {Deep} {Learning} {Loss} {Function} for {Highly} {Unbalanced} {Segmentations}},
	isbn = {978-3-319-67557-2 978-3-319-67558-9},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-67558-9_28},
	abstract = {Deep-learning has proved in recent years to be a powerful tool for image analysis and is now widely used to segment both 2D and 3D medical images. Deep-learning segmentation frameworks rely not only on the choice of network architecture but also on the choice of loss function. When the segmentation process targets rare observations, a severe class imbalance is likely to occur between candidate labels, thus resulting in sub-optimal performance. In order to mitigate this issue, strategies such as the weighted cross-entropy function, the sensitivity function or the Dice loss function, have been proposed. In this work, we investigate the behavior of these loss functions and their sensitivity to learning rate tuning in the presence of different rates of label imbalance across 2D and 3D segmentation tasks. We also propose to use the class re-balancing properties of the Generalized Dice overlap, a known metric for segmentation assessment, as a robust and accurate deep-learning loss function for unbalanced tasks.},
	language = {en},
	urldate = {2018-03-20},
	booktitle = {Deep {Learning} in {Medical} {Image} {Analysis} and {Multimodal} {Learning} for {Clinical} {Decision} {Support}},
	publisher = {Springer, Cham},
	author = {Sudre, Carole H. and Li, Wenqi and Vercauteren, Tom and Ourselin, Sebastien and Cardoso, M. Jorge},
	month = sep,
	year = {2017},
	doi = {10.1007/978-3-319-67558-9_28},
	pages = {240--248},
	file = {Full Text PDF:/home/fernando/Zotero/storage/QISRLZXY/Sudre et al. - 2017 - Generalised Dice Overlap as a Deep Learning Loss F.pdf:application/pdf;Snapshot:/home/fernando/Zotero/storage/GU5ZHHAV/978-3-319-67558-9_28.html:text/html}
}

@article{maninis_deep_2016,
	title = {Deep {Retinal} {Image} {Understanding}},
	volume = {9901},
	url = {http://arxiv.org/abs/1609.01103},
	doi = {10.1007/978-3-319-46723-8_17},
	abstract = {This paper presents Deep Retinal Image Understanding (DRIU), a unified framework of retinal image analysis that provides both retinal vessel and optic disc segmentation. We make use of deep Convolutional Neural Networks (CNNs), which have proven revolutionary in other fields of computer vision such as object detection and image classification, and we bring their power to the study of eye fundus images. DRIU uses a base network architecture on which two set of specialized layers are trained to solve both the retinal vessel and optic disc segmentation. We present experimental validation, both qualitative and quantitative, in four public datasets for these tasks. In all of them, DRIU presents super-human performance, that is, it shows results more consistent with a gold standard than a second human annotator used as control.},
	urldate = {2018-03-21},
	journal = {arXiv:1609.01103 [cs]},
	author = {Maninis, Kevis-Kokitsi and Pont-Tuset, Jordi and Arbeláez, Pablo and Van Gool, Luc},
	year = {2016},
	note = {arXiv: 1609.01103},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {140--148},
	file = {arXiv\:1609.01103 PDF:/home/fernando/Zotero/storage/23SJUZ7D/Maninis et al. - 2016 - Deep Retinal Image Understanding.pdf:application/pdf;arXiv.org Snapshot:/home/fernando/Zotero/storage/RH9V2I6L/1609.html:text/html}
}

@article{simonyan_very_2014,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2018-03-21},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1409.1556 PDF:/home/fernando/Zotero/storage/VIRJDK2W/Simonyan and Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf;arXiv.org Snapshot:/home/fernando/Zotero/storage/EUI9Z7WL/1409.html:text/html}
}